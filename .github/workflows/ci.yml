name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  NODE_ENV: test

jobs:
  validate:
    name: Build and Core Validation
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        node-version: [18, 20]  # Reduced matrix for efficiency
      fail-fast: false
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          cache-dependency-path: server/package-lock.json
      
      - name: Install dependencies
        run: |
          cd server
          npm ci --prefer-offline --no-audit
      
      - name: TypeScript type checking
        run: |
          cd server
          npm run typecheck
      
      - name: Build project
        run: |
          cd server
          npm run build
      
      - name: Run tests
        run: |
          cd server
          npm test
        timeout-minutes: 5
      
      - name: Validate MCP server startup (Unix)
        if: runner.os != 'Windows'
        run: |
          cd server
          # Use a cross-platform timeout approach with error capture
          if command -v timeout >/dev/null 2>&1; then
            timeout 10s npm run start:debug 2>&1 | head -20 || true
            exit_code=$?
            if [ $exit_code -eq 124 ]; then
              echo "‚úÖ Server startup timeout (expected)"
            else
              echo "‚ùå Server startup failed with exit code: $exit_code"
              echo "Server output (last 20 lines shown above)"
              exit 1
            fi
          elif command -v gtimeout >/dev/null 2>&1; then
            # macOS with coreutils installed
            gtimeout 10s npm run start:debug 2>&1 | head -20 || true
            exit_code=$?
            if [ $exit_code -eq 124 ]; then
              echo "‚úÖ Server startup timeout (expected)"
            else
              echo "‚ùå Server startup failed with exit code: $exit_code"
              echo "Server output (last 20 lines shown above)"
              exit 1
            fi
          else
            # Fallback: use background process with sleep and capture output
            npm run start:debug > startup_output.log 2>&1 &
            server_pid=$!
            sleep 10
            if kill -0 $server_pid 2>/dev/null; then
              echo "‚úÖ Server startup timeout (expected)"
              kill $server_pid 2>/dev/null || true
            else
              echo "‚ùå Server startup failed"
              echo "Server output:"
              cat startup_output.log | head -20
              exit 1
            fi
          fi
      
      - name: Validate MCP server startup (Windows)
        if: runner.os == 'Windows'
        run: |
          cd server
          $job = Start-Job -ScriptBlock { npm run start:debug }
          Start-Sleep -Seconds 10
          Stop-Job $job
          Remove-Job $job
          Write-Host "‚úÖ Server startup timeout (expected)"
        shell: powershell
      
      - name: Upload build artifacts
        if: matrix.os == 'ubuntu-latest' && matrix.node-version == '18'
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            server/dist/
            server/package.json
            server/package-lock.json
          retention-days: 7

  comprehensive-framework-tests:
    name: Comprehensive CAGEERF & MCP Integration Tests
    runs-on: ubuntu-latest
    needs: validate
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: server/package-lock.json
      
      - name: Install dependencies
        run: |
          cd server
          npm ci --prefer-offline --no-audit
      
      - name: Build project
        run: |
          cd server
          npm run build
      
      - name: Enhanced MCP Server Integration Tests
        run: |
          cd server
          echo "üß™ Running enhanced MCP server integration tests..."
          
          node -e "
            async function enhancedIntegrationTests() {
              const { ApplicationOrchestrator } = await import('./dist/orchestration/index.js');
              const { MockLogger } = await import('./dist/utils/index.js');
              console.log('üîç Test 1: Full server initialization sequence');
              
              const logger = new MockLogger();
              const orchestrator = new ApplicationOrchestrator(logger);
              
              await orchestrator.loadConfiguration();
              if (!orchestrator.config) {
                throw new Error('Configuration not loaded');
              }
              console.log('‚úÖ Configuration loaded successfully');
              
              await orchestrator.loadPromptsData();
              console.log(\`‚úÖ Prompts data loaded: \${orchestrator.promptsData ? orchestrator.promptsData.length : 0} prompts\`);
              
              await orchestrator.initializeModules();
              if (!orchestrator.mcpToolsManager) {
                throw new Error('MCP tools manager not initialized');
              }
              console.log('‚úÖ Modules initialized successfully');
              
              const healthInfo = await orchestrator.getDiagnosticInfo();
              if (!healthInfo || typeof healthInfo !== 'object') {
                throw new Error('Health diagnostics failed');
              }
              console.log(\`‚úÖ Health diagnostics collected: \${Object.keys(healthInfo).length} metrics\`);
              
              console.log('üéâ Enhanced integration tests completed successfully');
            }
            
            enhancedIntegrationTests().catch(error => {
              console.error('‚ùå Enhanced integration tests failed:', error.message);
              process.exit(1);
            });
          "
      
      - name: CAGEERF Framework Comprehensive Tests
        run: |
          cd server
          echo "üß™ Running comprehensive CAGEERF framework tests..."
          
          node -e "
            async function comprehensiveFrameworkTests() {
              const { CAGEERFAnalyzer } = await import('./dist/utils/cageerf-analyzer.js');
              const { TemplateGenerator } = await import('./dist/utils/template-generator.js');
              const { TemplateRepositoryBuilder } = await import('./dist/utils/template-repository.js');
              const { SemanticAnalyzer } = await import('./dist/utils/semanticAnalyzer.js');
              const { MockLogger } = await import('./dist/utils/index.js');
              console.log('üîç Test 1: CAGEERF Analyzer edge cases');
              
              const analyzer = new CAGEERFAnalyzer();
              
              const testCases = [
                'Simple prompt',
                'Context analysis goals execution evaluation refinement framework methodology',
                'A'.repeat(1000),  // Long input
                'üöÄ Analyze üìä the data with systematic approach! üéØ'  // With emojis
              ];
              
              for (let i = 0; i < testCases.length; i++) {
                const analysis = analyzer.analyzePrompt(testCases[i]);
                if (!analysis.compliance || !analysis.frameworkScore || analysis.overallCompliance === undefined) {
                  throw new Error(\`Invalid analysis structure for test case \${i + 1}\`);
                }
                if (analysis.frameworkScore < 0 || analysis.frameworkScore > 1) {
                  throw new Error(\`Invalid framework score: \${analysis.frameworkScore}\`);
                }
                console.log(\`‚úÖ Test case \${i + 1} passed (score: \${analysis.frameworkScore.toFixed(3)})\`);
              }
              
              console.log('üîç Test 2: Template Generator validation');
              const generator = new TemplateGenerator();
              const complexities = ['simple', 'intermediate', 'advanced'];
              const styles = ['structured', 'conversational', 'professional'];
              
              for (const complexity of complexities) {
                for (const style of styles) {
                  const template = await generator.generateTemplate({
                    useCase: \`Test \${complexity} \${style}\`,
                    domain: 'Testing',
                    complexity: complexity,
                    frameworkEmphasis: {
                      context: true, analysis: true, goals: true,
                      execution: true, evaluation: true, refinement: true, framework: true
                    },
                    templateStyle: style,
                    includePlaceholders: true
                  });
                  
                  if (!template.userMessageTemplate || typeof template.userMessageTemplate !== 'string') {
                    throw new Error('Invalid template content');
                  }
                  if (!template.qualityScore || template.qualityScore < 0 || template.qualityScore > 1) {
                    throw new Error(\`Invalid CAGEERF score: \${template.qualityScore}\`);
                  }
                  console.log(\`‚úÖ Template \${complexity}/\${style} passed (score: \${template.qualityScore.toFixed(3)})\`);
                }
              }
              
              console.log('üîç Test 3: Template Repository validation');
              const repository = TemplateRepositoryBuilder.buildRepository();
              if (!repository.templates || !Array.isArray(repository.templates)) {
                throw new Error('Invalid templates array');
              }
              console.log(\`‚úÖ Repository validation passed: \${repository.templates.length} templates\`);
              
              console.log('üîç Test 4: Semantic Analyzer enhanced functionality');
              const semanticAnalyzer = new SemanticAnalyzer(new MockLogger());
              const testPrompt = {
                id: 'test-prompt-001',
                name: 'Test Analysis Prompt',
                userMessageTemplate: 'Analyze the context, set goals, execute systematic evaluation',
                description: 'Test prompt for semantic analysis',
                category: 'test',
                arguments: [],
                systemMessage: 'Test system message'
              };
              
              const classification = semanticAnalyzer.classifyPrompt(testPrompt);
              if (!classification.executionType || classification.confidence === undefined) {
                throw new Error('Invalid classification structure');
              }
              if (!classification.cageerfAnalysis || classification.frameworkCompliance === undefined) {
                throw new Error('Missing CAGEERF integration');
              }
              console.log(\`‚úÖ Semantic analysis passed: \${classification.executionType} (confidence: \${classification.confidence.toFixed(3)})\`);
              
              console.log('üéâ Comprehensive CAGEERF framework tests completed successfully');
            }
            
            comprehensiveFrameworkTests().catch(error => {
              console.error('‚ùå CAGEERF framework tests failed:', error.message);
              process.exit(1);
            });
          "
      
      - name: MCP Tools Comprehensive Tests
        run: |
          cd server
          echo "üß™ Running comprehensive MCP tools tests..."
          
          node -e "
            async function comprehensiveMcpToolsTests() {
              const { McpToolsManager } = await import('./dist/mcp-tools/index.js');
              const { TemplateGenerationTools } = await import('./dist/mcp-tools/template-generation-tools.js');
              const { MockLogger } = await import('./dist/utils/index.js');
              console.log('üîç Test 1: MCP Tools Manager functionality');
              
              const toolCalls = [];
              const mockMcpServer = {
                tool: function(name, description, schema) {
                  toolCalls.push({ name, description, schema });
                  return {
                    name,
                    handler: async (args) => {
                      return {
                        content: [{ type: 'text', text: \`Mock response for \${name}\` }]
                      };
                    }
                  };
                }
              };
              
              const logger = new MockLogger();
              const toolsManager = new McpToolsManager(logger, mockMcpServer, {});
              
              const testPromptsData = [
                {
                  id: 'test-1',
                  name: 'Test Prompt 1',
                  content: 'Test content with context and analysis components',
                  description: 'Test prompt description'
                }
              ];
              
              const testConvertedPrompts = [
                {
                  id: 'test-1',
                  name: 'Test Prompt 1',
                  content: 'Test content',
                  description: 'Test description',
                  category: 'test',
                  executionMode: 'template'
                }
              ];
              
              const testCategories = [
                { name: 'test', description: 'Test category' }
              ];
              
              toolsManager.updateData(testPromptsData, testConvertedPrompts, testCategories);
              toolsManager.registerAllTools();
              
              if (toolCalls.length === 0) {
                throw new Error('No tools were registered');
              }
              console.log(\`‚úÖ MCP Tools Manager registered \${toolCalls.length} tools\`);
              
              const registeredNames = toolCalls.map(t => t.name);
              const essentialTools = ['update_prompt', 'list_prompts', 'execute_prompt'];
              
              for (const tool of essentialTools) {
                if (!registeredNames.includes(tool)) {
                  console.log(\`‚ö†Ô∏è  Essential tool missing: \${tool}\`);
                } else {
                  console.log(\`‚úÖ Essential tool found: \${tool}\`);
                }
              }
              
              console.log('üîç Test 2: Template Generation Tools validation');
              const templateTools = new TemplateGenerationTools(logger, mockMcpServer);
              const beforeCount = toolCalls.length;
              
              templateTools.registerAllTools();
              const templateToolsCount = toolCalls.length - beforeCount;
              
              if (templateToolsCount === 0) {
                throw new Error('No template generation tools were registered');
              }
              console.log(\`‚úÖ Template Generation Tools registered \${templateToolsCount} additional tools\`);
              
              console.log('üéâ Comprehensive MCP tools tests completed successfully');
            }
            
            comprehensiveMcpToolsTests().catch(error => {
              console.error('‚ùå MCP tools tests failed:', error.message);
              process.exit(1);
            });
          "
      
      - name: Performance and Memory Tests
        run: |
          cd server
          echo "üß™ Running performance and memory tests..."
          
          node -e "
            async function performanceTests() {
              const { CAGEERFAnalyzer } = await import('./dist/utils/cageerf-analyzer.js');
              const { TemplateGenerator } = await import('./dist/utils/template-generator.js');
              console.log('‚è±Ô∏è  Starting performance tests...');
              
              const analyzer = new CAGEERFAnalyzer();
              const generator = new TemplateGenerator();
              
              // Performance benchmark
              const testPrompts = [
                'Simple analysis task',
                'Complex multi-faceted analysis requiring comprehensive context evaluation, systematic goal setting, detailed execution planning, thorough evaluation criteria, and iterative refinement processes',
                'Medium complexity prompt with CAGEERF elements'
              ];
              
              console.log('üìä Analysis Performance:');
              for (let i = 0; i < testPrompts.length; i++) {
                const start = Date.now();
                const analysis = analyzer.analyzeText(testPrompts[i]);
                const duration = Date.now() - start;
                console.log(\`   Prompt \${i + 1}: \${duration}ms (score: \${analysis.frameworkScore.toFixed(3)})\`);
                
                if (duration > 1000) {
                  console.log(\`‚ö†Ô∏è  Warning: Analysis took \${duration}ms (threshold: 1000ms)\`);
                }
              }
              
              // Memory usage test
              const initialMemory = process.memoryUsage().heapUsed;
              
              for (let i = 0; i < 50; i++) {
                analyzer.analyzePrompt('Memory test prompt with comprehensive analysis components');
                await generator.generateTemplate({
                  useCase: 'Memory Test',
                  domain: 'Testing',
                  complexity: 'simple',
                  frameworkEmphasis: { context: true, analysis: true, goals: true, execution: true, evaluation: true, refinement: true, framework: true },
                  templateStyle: 'structured'
                });
              }
              
              global.gc && global.gc();
              const finalMemory = process.memoryUsage().heapUsed;
              const memoryIncrease = finalMemory - initialMemory;
              
              if (memoryIncrease > 25 * 1024 * 1024) {
                console.log(\`‚ö†Ô∏è  Potential memory leak: \${Math.round(memoryIncrease / 1024 / 1024)}MB increase\`);
              } else {
                console.log(\`‚úÖ Memory usage acceptable: \${Math.round(memoryIncrease / 1024 / 1024)}MB increase for 50 operations\`);
              }
              
              console.log('‚úÖ Performance and memory tests completed successfully');
            }
            
            performanceTests().catch(error => {
              console.error('‚ùå Performance tests failed:', error.message);
              process.exit(1);
            });
          " --expose-gc

  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: server/package-lock.json
      
      - name: Install dependencies
        run: |
          cd server
          npm ci --prefer-offline --no-audit
      
      - name: Check for sensitive files
        run: |
          if find . -name "*.env*" -o -name "*.key" -o -name "*.pem" -o -name "*.p12" | grep -v node_modules | grep -q .; then
            echo "‚ùå Sensitive files found in repository"
            find . -name "*.env*" -o -name "*.key" -o -name "*.pem" -o -name "*.p12" | grep -v node_modules
            exit 1
          else
            echo "‚úÖ No sensitive files found"
          fi
      
      - name: Validate TypeScript files
        run: |
          cd server
          find src -name "*.ts" -exec echo "Checking {}" \;
          if find src -name "*.js" | grep -q .; then
            echo "‚ùå JavaScript files found in TypeScript source directory"
            find src -name "*.js"
            exit 1
          else
            echo "‚úÖ All source files are TypeScript"
          fi
      
      - name: Check package.json consistency
        run: |
          cd server
          if npm ls --depth=0 >/dev/null 2>&1; then
            echo "‚úÖ Package.json dependencies are consistent"
          else
            echo "‚ùå Package.json dependency issues found"
            npm ls --depth=0 || true
            exit 1
          fi
      
      - name: Validate build artifacts
        run: |
          cd server
          npm run build
          if [ -d "dist" ] && [ -f "dist/index.js" ]; then
            echo "‚úÖ Build artifacts generated successfully"
          else
            echo "‚ùå Build artifacts missing"
            ls -la dist/ || echo "dist directory not found"
            exit 1
          fi